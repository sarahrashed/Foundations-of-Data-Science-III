{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c0cc67",
   "metadata": {
    "hide_input": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display_html, display, Math, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d3b5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11aa9f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{margin}\n",
    "These sections and many that follow draw extensively on [Think Bayes](https://greenteapress.com/wp/think-bayes) by Allen B. Downey.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdace8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On a visit to the doctor, we may ask, \"What is the probability that I have disease X?\" but what we really mean is \"How certain should I be that I have disease X?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760798a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Or, before digging a well, we may ask, \"What is the probability that I will strike water?\" but what we are really asking is \"How certain should I be that I will strike water?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcecea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The key insight is that either we do, or do not, have disease X and either will, or will not, strike water, and what we can determine is the level of certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e24ce0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Bayes' Theorem__ will be the tool we use to answer questons like this and will form the foundation of the next 6 weeks of this course! It is the basis of the Bayesian view of probability.\n",
    "\n",
    "In this view, we are using probability to encode a \"degree of belief\" or a \"state of knowledge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267417b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review of Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f87111",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The Chain Rule\n",
    "Recall from many weeks ago, the definition of conditional probaility:\n",
    "\n",
    "$$ P(A \\,\\vert\\, B) = \\frac{P(A, B)}{P(B)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aef36a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From there we derived the chain rule by multiplying both sides by $P(B)$:\n",
    "\n",
    "$$ P(A, B) = P(A \\,\\vert\\, B)\\; P(B) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548caef3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6bcec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now recall the fact that the conjuction (joint probability) is commutative:\n",
    "\n",
    "$$ P(A, B) = P(B, A)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218549c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's then use the chain rule to expand both sides:\n",
    "\n",
    "$$ P(A \\,\\vert\\, B)\\; P(B) = P(B \\,\\vert\\, A)\\; P(A) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aed0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And then divide through by $P(B)$:\n",
    "\n",
    "$$ P(A \\,\\vert\\, B)\\; =  \\frac{P(B\\,\\vert\\,A) \\; P(A)}{P(B)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cefd104",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is Bayes' Theorem (or Bayes' Rule), and we're about to find out why it's so powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe17ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Cookie Problem\n",
    "Let's use the Bayesian framework to answer a basic probability question first. \n",
    "\n",
    "Suppose there are two bowls of cookies:\n",
    "- The first bowl contains 30 vanilla cookies and 10 chocolate cookies\n",
    "- The second contains 20 vanilla cookies and 20 chocolate cookies\n",
    "\n",
    "If you choose a bowl at random, and then grab a cookie at random and get a vanilla cookie, what is the probability it came from the first bowl?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679f597",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively, we know that the first bowl had more vanilla cookies, so we should expect it to be more than a 50% chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0ac66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's solve this using Bayes' Theorem. What we want to solve for is:\n",
    "\n",
    "$$ P(\\text{first bowl} \\vert \\text{vanilla cookie}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a094fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using Bayes':\n",
    "\n",
    "$$P(\\text{first bowl} \\vert \\text{vanilla cookie})\\ = \\frac{P(\\text{vanilla cookie} \\vert \\text{first bowl})\\;P(\\text{first bowl})}{P(\\text{vanilla cookie})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39a91f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now have three probabilities we need to determine:\n",
    "- $P(\\text{first bowl})$ which is one bowl out of two, so 1/2.\n",
    "- $P(\\text{vanilla cookie} \\vert \\text{first bowl})$ which is 30 out of 40 cookies, so 3/4.\n",
    "- $P(\\text{vanilla cookie})$ which is a litte tougher, since it's the combined probability of vanillia cookies from either bowl. So let's caculate that:\n",
    "\n",
    "$$P(\\text{vanilla cookie}) = P(\\text{vanilla cookie} \\vert \\text{first bowl})\\;P(\\text{first bowl}) + P(\\text{vanilla cookie} \\vert \\text{second bowl})P(\\text{second bowl}) $$\n",
    "\n",
    "$$ = (3/4)(1/2)+(1/2)(1/2) =5/8$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc805707",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's put it all together now:\n",
    "\n",
    "$$P(\\text{first bowl} \\vert \\text{vanilla cookie})\\ = \\frac{P(\\text{vanilla cookie} \\vert \\text{first bowl})P(\\text{first bowl})}{P(\\text{vanilla cookie})} = \\frac{(1/2)(3/4)}{5/8} = 3/5$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba6aae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just like we suspected, because the first bowl had more vanillia cookies, it was more likely that our cookie came from the first bowl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21d502",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As an exercise, let's try a less intuitive problem. There is a rare genetic disease that affects 1 in 10,000 people. There's a diagnostic test that is 99% accurate (in the sense that if you have the disease it will be positive 99% of them time and if you don't it will be negative 99% of the time). You take the test and it comes back positive for the disease. What is the probability you have the disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8c247",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using Bayes':\n",
    "\n",
    "$$P(\\text{Rare Genetic Disease} \\vert \\text{Positive Test})\\ = \\frac{P(\\text{Positive Test} \\vert \\text{Rare Genetic Disease})\\;P(\\text{Rare Genetic Disease})}{P(\\text{Positive Test})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e1b64",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first probabilities are given, but again we need to calculate that denominator:\n",
    "\n",
    "$$ P(\\text{Positive Test}) = P(\\text{Positive Test} \\vert \\text{Have Disease})P(\\text{Have Disease}) + P(\\text{Positive Test} \\vert \\text{Don't Have Disease})P(\\text{Don't have disease}) $$\n",
    "\n",
    "$$ = (0.99)(1/10000)+(0.01)(9999/10000) = 0.01$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d72f85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Putting it all together\n",
    "\n",
    "$$P(\\text{Rare Genetic Disease} \\vert \\text{Positive Test})\\ = \\frac{(0.99)(1/10000)}{0.01} = 0.0099$$\n",
    "\n",
    "So theres only a 1% chance you actually have the rare disease despite the positive test result on a 99% accurate test! In fact, even if the test was 99.9% accurate, a positive result would only be a 9% chace. The **prior knowledge** that the disease is rare is absolutely crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6f6a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem to update probability (Diachronic Bayes)\n",
    "While being able to solve questions like the ones raised in the problems above is useful, the main way Bayes' Theorem is used in Bayesian probability is as a way to update the probability of a hypothesis H, given some data D. This is sometimes called \"Diachronic Bayes\" which means \"related to change over time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7489247",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a general framework, we re-write Bayes' Theorem as:\n",
    "\n",
    "$$ P(H \\,\\vert\\, D)\\; =  \\frac{P(H)P(D\\,\\vert\\,H) \\; }{P(D)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ae906",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this diachronic framework, these terms are known by specific names (these terms will come up over and over again, make sure to remember them):\n",
    "- $P(H)$, the probability of the hypothesis before we see the data, called the **prior** probability\n",
    "- $P(H \\vert D)$, the probability of the hypothesis after we see the data, called the **posterior** probability\n",
    "- $P(D \\vert H)$, the probabilitiy of the data under the hypothesis, called the **likelihood**\n",
    "- $P(D)$, the **total probability of the data** under any hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f782d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Prior\n",
    "\n",
    "The **prior** is often the trickiest portion of this equation to pin down. \n",
    "\n",
    "Sometimes it can be computed exactly as in the cookie bowl problem, where we were equally likely to pick each bowl. \n",
    "\n",
    "But what if we chose bowls proportinally to their size? We would need to guess at their sizes to establish the prior. \n",
    "\n",
    "Other times, people might disagree about which background information is relevent to the problem at hand. In fact in many cases, people will use a uniform prior!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc9faf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The Likelihood\n",
    "\n",
    "The **likelihood** is usually well defined and can be computed directly. In the cookie problem we know the cookies in each bowl, so we can compute the probabilites under each hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10663adf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Total Probability\n",
    "\n",
    "Finally, determining the **total probability** of the data is often a lot more difficult than you might expect because we often don't know what every possible hypothesis is. \n",
    "\n",
    "However, usually the goal is to pin down a set of **mutually exclusive** and **collectively exhaustive** hypotheses, meaning a set of hypotheses where only one of them can be true, and one of them must be true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0376fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, over a set of *i* hypotheses, we say:\n",
    "\n",
    "$$P(D) = \\sum_i{P(H_i)P(D \\vert H_i)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e796788",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The Bayesian Update\n",
    "\n",
    "Overall, the process of generating a posterior probability from a prior probability using data is called a **Bayesian update.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc940a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Tables\n",
    "Often when we work with Bayes' theorem to update probabilities (i.e. when we do a Bayesian update), we'll want to keep track of the probabilities of hypotheses as we update them using our data. \n",
    "\n",
    "This table that keeps track of the probabilities of all hypotheses as we update them using our data is called a **Bayes table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0acba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's go step by step to create a Bayes table for the cookie problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e973819",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we need a table of all our hyptheses, one row for each hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efb6db1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first bowl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second bowl</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [first bowl, second bowl]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(index=['first bowl', 'second bowl'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16e4db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we add the prior probabilities of each hypothesis. Our prior is that it was equally likely to get a vanilla cookie from either bowl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b970eb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first bowl</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second bowl</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prior\n",
       "first bowl     0.5\n",
       "second bowl    0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['prior'] = 1/2, 1/2\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4112d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **likelihood** of each hypothesis is the fraction of cookies in each bowl that is vanilla.   For example, \n",
    "\n",
    "$$ P(D\\,\\vert\\,\\text{First Bowl was chosen}) = \\frac{30}{40} = 0.75$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433318ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prior  likelihood\n",
       "first bowl     0.5        0.75\n",
       "second bowl    0.5        0.50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['likelihood'] = 30/40, 20/40\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa34a7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now lets compute the \"unnormalized posteriors.\" This is just a term for the top half of the Bayes' theorem formula: the prior multiplied by the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc250d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the first term of the unnormalized posteriors is:\n",
    "\n",
    "$$ P(D\\,\\vert\\,\\text{First Bowl was chosen}) \\, P(\\text{First Bowl was chosen}) = 0.5 \\cdot 0.75 = 0.375$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b8b316",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prior  likelihood  unnormalized\n",
       "first bowl     0.5        0.75         0.375\n",
       "second bowl    0.5        0.50         0.250"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['unnormalized'] = table['prior'] * table['likelihood']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea2c02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The final missing piece is to divide by the total probability of the data. \n",
    "\n",
    "What we are doing is to **normalize** the posteriors so that they sum up to 1.\n",
    "\n",
    "To find the total probability of the data we directly sum over the unnormalized posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab931177",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_data = table['unnormalized'].sum()\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f89e67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This gives us 5/8, just like we calculated before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ba105",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we can use the total probability of the data to get the posterior probability of each hypthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14bf978f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnormalized</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second bowl</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prior  likelihood  unnormalized  posterior\n",
       "first bowl     0.5        0.75         0.375        0.6\n",
       "second bowl    0.5        0.50         0.250        0.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['posterior'] = table['unnormalized'] / prob_data\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16dde4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And so we see, the posterior probability of the first bowl, given that we observed a vanilla cokie, is 0.6, the same as when we used Bayes' theorem directly before. \n",
    "\n",
    "Notice that the posteriors add up to 1 (as we should expect given mutually exclusive and collectivly exhaustive hypotheses), which is why the total probability of the data is sometimes called the \"normalizing constant\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "scroll": false,
   "theme": "serif",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
